# Reproducibility

## Environment Setup

### Official Environment Creation
To ensure reproducible results, use the pinned `environment.yml`:

```bash
micromamba create -n geo -f environment/environment.yml -y
micromamba activate geo
```

### Environment Details
- **Python**: 3.12
- **NumPy**: 2.3.* (pinned for compatibility with `numba 0.63.1` — required for `libpysal`)
- **Spatial Stack**: `libpysal`, `esda`, `spreg` (no pip; all conda-forge)
- **Data Stack**: `geopandas`, `shapely`, `pyproj`, `fiona`, `rasterio`, `gdal` (osgeo)
- **Viz**: `matplotlib`, `seaborn`, `jupyterlab`
- **Stats**: `pandas`, `scipy`, `scikit-learn`, `statsmodels`

### Verifying Installation
After activation, test:
```bash
python -c "import numpy, numba; print('numpy', numpy.__version__, 'numba', numba.__version__)"
python -c "import libpysal; from libpysal.weights import KNN, Queen; import esda, spreg; print('PySAL OK')"
python -c "import geopandas, shapely, pyproj, fiona, rasterio; from osgeo import gdal; print('Geo stack OK')"
```

## Data Cleaning & Wrangling

### Sample Flow and Audit Trail

The analysis follows a rigorous two-stage sample definition:

| Stage | Action | N_remaining | N_dropped | Reason |
|-------|--------|-------------|-----------|--------|
| **0** | Initial load from `listings_clean.parquet` | 24,987 | — | Starting dataset |
| **1** | Price parsing (exclude NaN/unparseable) | **18,940** | 6,047 | Invalid or missing price values |
| **2** | Winsorization (p=0.5%, p=99.5%) | **18,765** | 175 | Extreme outliers (€19–€999 price range) |
| **3** | Feature engineering + dropna on model covariates | **15,641** | 3,124 | Missing log_price or any of 140 model features |

**Detailed audit trail**: see `outputs/tables/sample_flow.csv`

#### Sample Definitions

1. **"Price-Valid" Sample (N=18,940)**
   - Used in: `scripts/04_spatial_autocorr_morans_i.py` (Moran's I listing-level analysis)
   - Includes all listings with valid and winsorized prices
   - Sufficient for neighbourhood-level aggregation but not for feature-complete regression

2. **"Model-Complete" Sample (N=15,641)**
   - Used in: `scripts/03_ols_price_analysis.py`, `scripts/05_lm_diagnostic_tests.py`, `scripts/06_morans_i_subset_consistency_check.py`, `scripts/07_spatial_models_sar_sem.py`
   - Includes only listings with valid prices **and complete covariate data** (property, host, room type, location, neighbourhood features)
   - Ensures consistency across all spatial diagnostic tests (Moran's I, LM-lag, LM-error) and model estimation (OLS, SAR, SEM)
   - Sample size reduction of 3,124 due to missing values in: `bedrooms`, `beds`, `bathrooms`, `review_scores_rating`, `neighbourhood_cleansed`, and derived features

**Key principle**: All diagnostic tests and spatial models (scripts 05–07) operate on the same sample (N=15,641) to ensure valid comparisons.

## Run pipeline

The main reproducible pipeline includes:

1. **QC spatial sanity checks**:
```bash
python scripts/01_verify_spatial_data.py
```

2. **Generate static report figure** (overview + inset with price quantiles):
```bash
python scripts/02_make_static_map_overview_inset.py
```

3. **Full end-to-end ETL** (cleaning, enrichment, spatial joins, aggregation):
```bash
jupyter notebook notebooks/05_final_pipeline.ipynb
```

### Inputs & Outputs

**Inputs** (assumed to be in `data/original/`):
- `calendar.csv`, `listings.csv`, `reviews.csv`, `neighbourhoods.geojson`

**Outputs**:
- Processed datasets: `data/processed/*.parquet`, `data/processed/*.geojson`
- Static report figures: **`reports/figures/*.png`** (unified location)

## Notes
- Distances/areas must be computed in a projected CRS (meters), not EPSG:4326.
- Always check CRS, geometry validity, missing values and outliers.
- **NumPy Pinning**: NumPy is pinned to `2.3.*` for compatibility with `numba 0.63.1` (required by `libpysal`). Do not upgrade NumPy without re-testing the full spatial weights and analysis pipeline.

### Data & Environment Management for Reproducibility
- Raw InsideAirbnb files (e.g., `calendar.csv`, `reviews.csv`, `listings.csv`) are not tracked in git due to size/licensing; place them locally in `data/original/`.
- The project is fully reproducible: all processed datasets in `data/processed/` can be regenerated by running the pipeline scripts/notebooks.
- Small web-ready artifacts (e.g., `data/processed/neighbourhoods_enriched.geojson` and `data/processed/listings_points_enriched_sample.geojson`) may be tracked to support fast webmap rendering.
- Final report figures are stored in `reports/figures/`.
